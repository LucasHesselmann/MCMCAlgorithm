\chapter{The Metropolis-Hastings method}
\label{sec:Metropolis-HastingsMethod}


This chapter is devoted to introduce the Metropolis-Hastings (MH) method. In Section \ref{MH-MCMCPrinciple} we will give an overview on the fundamental methodology and the historic motivation of the MH method and some remarks on the Markov chain Monte Carlo methods in general. The general MH algorithm is stated in Section \ref{MH-TheMetropolis-HastingsAlgo}. To show well-posedness of the MH algorithm, i.e., convergence to an equilibrium, the generated Markov chain has to fulfill some convergence properties (see Section \ref{MH-ConvergenceProperties}). The heart of the Metropolis-Hastings algorithm is the choice of the proposals. In this work we consider the random walk proposals (see Section \ref{MH-RWM}) and the Langevin proposals (see Section \ref{MH-MALA}) leading to the random walk Metropolis (RWM) algorithm and the Metropolis-adjusted Langevin algorithm (MALA), respectively.


\section{The Markov chain Monte Carlo principle}
\label{MH-MCMCPrinciple}

Markov chain Monte Carlo (MCMC) methods are a class of algorithms for sampling from probability distributions by constructing a Markov chain which has the desired target distribution as its equilibrium distribution. So every step of the socalled Metropolis-Hastings Markov chain will be a sample distributed according to the equilibrium distribution which is the desired target distribution.

The basic working principle underlying the MCMC methods is to generate an ergodic Markov chain with invariant distribution equal to the target distribution. This can be expressed as follows: For an arbitrary starting value $x^0$, a chain $ \{ x^{k} \}_{k \geq 0} $ is generated using a transition kernel with the target distribution as stationary distribution, which ensures the convergence in distribution of $ \{ x^{k} \}_{k \geq 0} $ to a random variable from the target distribution.

The principle of MCMC methods originated with the classic paper of Nicholas Metropolis, Arianna W.\,Rosenbluth, Marshall N.\,Rosenbluth, Augusta H.\,Teller and Edward Teller~\autocite{Metropolis1953} in 1953. It was used to simulate the configuration of states for a system of idealized particles. The so-called Metropolis algorithm, introduced in this paper, formed the basis for statistical mechanics simulations of large atomic and molecular systems which are useful in describing the properties of gases, fluids, mixtures of fluids, solids, and even the interior of stars. Theses expensive calculations became feasible through the invention of computers like the MANIAC at Los Alamos National Lab where the Metropolis algorithm was run for the first time~\autocites{MCAtWork1987, UlamNeumannMC1987}. 
The key contribution of Metropolis et al.\,was a change in the methodology: instead of choosing configurations randomly, then weighting them according to the Boltzman distribution, they choosed configurations with a probability according to the Boltzman distribution and weighted them evenly. This change set the sampling focus on the low-energy configurations, which contribute the most to the Boltzman average which resulted in inproved convergence of the simulation for the specific case of the canonical ensemble. In 1970, W.\,K.\,Hastings extended this methodology to general probability distributions~\autocite{Hastings1970}. Further MCMC methods are the Gibbs sampler, the slice sampler or the reversible jump MCMC method (see~\autocite{Robert2005}).

In the sequel, we introduce the Metropolis-Hastings algorithm where the transition kernel used for the generation of the Markov chain is realized by a proposal and accept-reject step. This combination of proposing a suitable candidate and prefering good candidates but not excluding the other ones, gives the recipe for an ergodic Markov chain under suitable assumptions on the proposals.

\section{The Metropolis-Hastings algorithm}
\label{MH-TheMetropolis-HastingsAlgo}

The Metropolis-Hastings algorithm is a rather general algorithm as no specific proposals are given. This will be done later by introducing two different types of more or less naives proposals: RWM and MALA. Nevertheless, we first adress the important issue of theoretical validity for all types of Metropolis-Hastings algorithms. For a more detailed introduction and missing definitions see~\autocite{Robert2005}.

Let $ \left( E, \mathcal{B}(E) \right) $ be a measurable space equipped with the Borel-$\sigma$-algebra where $ E \subset \mathbb{R}^{N} $ and the densities are taken with respect to the $N$-dimensional Lebesgue measure $\lambda^{N}(dx)$. Let $ \pi^{N}(dx) $ be the $N$-dimensional (target) distribution on $ E $ which is absolute continuous with respect to the Lebesgue measure, i.e., $ \pi^{N}(dx) \varpropto \pi^{N}(x) \; \lambda^{N}(dx) $. A (Markov) transition kernel on~$\left( E, \mathcal{B}(E) \right) $ is a map $ P : E \times \mathcal{B}(E)  \to [0,1]$ such that:
\begin{enumerate}
 \item[(i)] for any $A \in \mathcal{B}(E)$: $P(\cdot, A) $ is measurable,
 \item[(ii)] for any $ x \in E $: $P(x, \cdot)$ is a probability measure on~$\left( E, \mathcal{B}(E) \right) $.
\end{enumerate}
Probabilities for a Markov chain with transition kernel~$P$ started in~$x \in E$ are denoted by~$ \mathbb{P}_x $ and in the sequel, we will use (Markov) chain and transition kernel synonymously. Let $ Q : E \times \mathcal{B}(E) $ be an arbitrary transition kernel on $\left( E, \mathcal{B}(E) \right) $ satisfying for any $ x \in E $ and $ A \in \mathcal{B}(E) $
\begin{equation}
\label{MH - proposal kernel}
 Q(x,A) \geq 0, \quad Q(x, E) = 1,
\end{equation}
which generates potential transitions for a discrete time Markov chain evolving on $ E $.  We will assume that $ Q(x, \, \cdot \,) $ is absolutely continuous, with density $ q(x,y) $  with respect to the Lebesgue measure $ \lambda^{N}$ and we call $Q$ the proposal transition kernel.

The Metropolis-Hastings algorithm proceeds as follows. Starting from an initial state $ x^{0,N} \in E $, for every current state $x$ proposals $y$ are generated according to the transition kernel $ q (x, y) $ and in a second step accepted or rejected such that the resulting Markov chain $ x^{N} := \{ x^{k,N} \}_{k} $ has the target $ \pi^{N} $ as invariant distribution.


\IncMargin{1em}
\begin{algorithm}[htb]
\TitleOfAlgo{Metropolis-Hastings}
\DontPrintSemicolon

\KwData{Initial state $ x^{0,N} $, proposal kernel $ q(x,y) $ and \mbox{number of iterations $ M > 0 $}}
\KwResult{$\pi^{N}$-invariant Markov chain $ \{ x^{k,N} \}_{0 \leq k \leq M} $}

\BlankLine

\For{$ k \leftarrow 1 $ \KwTo $M$}
{
  Generate proposal: $ y^{k,N} \stackrel{D}{\thicksim} q(x^{k,N}, \cdot \;) $\;
  Set acceptance probability:
  \begin{equation*}
   \alpha^{N} ( x^{k,N}, y^{k,N} ) := 1 \wedge \dfrac{\pi^{N}(y^{k,N}) q(y^{k,N},x^{k,N}) }{\pi^{N}(x^{k,N}) q(x^{k,N},y^{k,N})}.    
  \end{equation*}\label{MHAlgo-AcceptanceProba}
  \emph{Acceptance-rejection step}\;
  Generate $ U \stackrel{D}{\thicksim} \text{Unif}(0,1) $\;
  \If { $ U < \alpha^{N} ( x^{k,N}, y^{k,N} ) $ }{ accept and set $ x^{k+1,N} = y^{k,N} $}
  \Else {reject and set $ x^{k+1,N} = x^{k,N} $}

}
\caption{Metropolis-Hastings algorithm with general proposals}\label{Algo-MH}
\end{algorithm}\DecMargin{1em}

The distribution $ Q(x,dy) $ is called the proposal distribution and the probability 
\begin{equation}
 \label{MH-Acceptance probability definition}
 \alpha^{N}(x,y)  := 1 \wedge \dfrac{\pi^{N}(y) q(y,x) }{\pi^{N}(x) q(x,y)}.
\end{equation}
 the Metropolis-Hastings acceptance probability. This algorithm always accepts proposals $y$ such that the ratio $ \pi^{N}(y) / q(x,y) $ is increased, compared with the current state ratio $ \pi^{N}(x) / q(y,x) $. An important feature of the Metropolis-Hastings algorithm is that it may accept proposals $y$ such that this ratio is decreased.

\begin{rem}
\label{Rem-Omitting constants in densities}
 Note that neither the target disribution $ \pi^{N}(dx) $ nor the proposal transition kernel $ Q(x,dy) $ have to be normalised as we take the ratio of densities in step \ref{MHAlgo-AcceptanceProba} of the Metropolis-Hastings Algorithm~\ref{Algo-MH}. Every normalising constant will be cancelled out. Since the calculation of such normalising constants corresponds to calculating high-dimensional integrals, e.g. by Monte Carlo integration, this is a real advantage of Algorithm~\ref{Algo-MH}. For the sake of simplicity, we will assume that $ \pi^{N}(dx) $ and $ Q(x,dy) $ are normalized.
\end{rem}

To avoid theoretical difficulties, we make the convention that the acceptance probability $ \alpha^{N}(x,y) $ is equal to 0 when either $ \pi^{N}(x) $ or $ \pi^{N}(y) $ are null.

\begin{rem}
\label{Rem-SupportOfProposals}
However it is necessary, that every area in the support of the target distribution $ \pi^{N} $ can be reached by the proposal transition kernel $ Q(x,dy) $, i.e.,
\begin{equation*}
 \text{supp} (\pi^{N}) \subset \bigcup_{x \in \text{supp} (\pi^{N}) } \text{supp} (Q(x, \, \cdot \,)).
\end{equation*}
This is a minimal necessary condition for exploring the whole the target distribution and hence for convergence and ergodicity.

Moreover it is easier for the MH algorithm if the support of the target distribution $ \pi^{N} $ is connected. In the case of an unconnected support, one has to verify that the different connected components of the support of $ \pi^{N} $ are linked by the proposal kernel. We thus assume for the sake of simplicity that the support of the target distribution is connected.
 
\end{rem}


We claimed that the Markov chain $ x^{N} $ has the target distribution $ \pi^{N} $ as invariant distribution. Therefore we introduce the transition kernel of $ x^{N} $ denoted by
\begin{align}
\label{MH-TransitionKernelOfMHChain}
 P^{N}(x,dy) & \; = \alpha^{N}(x,y) Q(x, dy) + r^{N}(x)\delta_{x}(dy) \\
 & \; = \alpha^{N}(x,y) q(x,y) \; \lambda^{N}(dy) + r^{N}(x)\delta_{x}(dy),
\end{align}

where $ r^{N}(x):= \int_{E} \left( 1 - \alpha^{N}(x,y) \right) q(x,y) \; \lambda^{N}(dx) $ represents the probability to stay at the current position.

By a straight forward calculation, one can see, that the Metropolis-Hastings Algorithm~\ref{Algo-MH} produces a Markov chain $ x^{N} $ which fulfills the \emph{detailed balance condition} with respect to $ \pi^{N} $, i.e.,
\begin{equation}
 \pi^{N}(dx) P^{N}(x,dy) = \pi^{N}(dy) P^{N}(y,dx).
\end{equation}

\begin{proof}
 Let $ x, y \in E $ and $ x \ne y $, then
 \begin{align*}
  \pi^{N}(dx) P^{N}(x,dy) & \; = \left( \pi^{N}(x) \, \lambda^{N}(dx) \right)  \left( \alpha^{N}(x,y) q(x,y) \, \lambda^{N}(dy) \right) \\
  & \; = \pi^{N}(x)  q(x,y) \left( 1 \wedge \dfrac{\pi^{N}(y) q(y,x) }{\pi^{N}(x) q(x,y)} \right) \, \lambda^{N}(dx) \lambda^{N}(dy) \\
  & \; = \left( \pi^{N}(x)  q(x,y) \wedge \pi^{N}(y) q(y,x) \right) \, \lambda^{N}(dx) \lambda^{N}(dy),
 \end{align*}
 which is symmetric in $x$ and $y$.

\end{proof}

Hence, the Markov chain $ x^{N} $ generated by the Metropolis-Hastings Algorithm \ref{Algo-MH} is $ \pi^{N} $-invariant, i.e.,

\begin{equation}
 \pi^{N} (A) = \int_{E} P^{N}(x,A) \pi^{N}(dx)
\end{equation}
for any $ A \in \mathcal{B}(E) $.



\subsection{Convergence and ergodicity properties}
\label{MH-ConvergenceProperties}

In the introduction of this chapter, we stated that the general working principle of MCMC methods is to generate ergodic and $\pi^{N}$-invariant Markov chains to sample from the target distribution~$\pi^{N}$. Therefore, we have shown that the transition kernels~$P^{N}$ of the Metropolis-Hastings~(MH)~chain as defined in~(\ref{MH-TransitionKernelOfMHChain}) fulfill the detailed balance condition with respect to the target~$\pi^{N}$ and is, hence, $\pi^{N}$-invariant. To deduce, that the MH~chain is also ergodic and that the corresponding transition kernels~$P^{N}$ converge to the invariant distribution~$\pi^{N}$, we have to introduce some more notation and theoretical results on Markov chains and the proposal kernels~$Q$ and the invariant distribution~$\pi^{N}$ have to fulfill some regularity and positivity conditions. The development in this section is based primarily on Robert and Casella~\autocite{Robert2005}~(Chapter~6~and~7) and Tierny~\autocite{Tierny1994}; further definitions and a more comprehensive depiction of this topic can be found there.


To start off, we need some more notation and definitions. We are considering as above a general state space~$ \left( E, \mathcal{B}(E) \right) $ equipped with the Borel-$\sigma$-algebra where $ E \subset \mathbb{R}^{N} $. General state space means locally compact spaces to distinguish from countable state spaces. On this state space are several (Markov) transition kernels defined: the proposal transition kernel~$Q$ as defined in~(\ref{MH - proposal kernel}) and the MH~transition kernel~$P^{N}$ as defined in~(\ref{MH-TransitionKernelOfMHChain}). These transition kernels define a probability measure on~$ \left( E, \mathcal{B}(E) \right) $ for every~$ x \in E $. To measure the distance between two measures $\mu$ and $\nu$ on ~$ \left( E, \mathcal{B}(E) \right) $  and hence to quantify if a certain measure converges towards a second, we use the \textit{total variation distance} defined as:
 \begin{equation}
  \left\| \mu - \nu \right\|_{TV} := \sup_{A \in \mathcal{S}} \left| \mu(A) - \nu(A) \right|.
 \end{equation}
The notation~$\{ A_n \; i.o. \}$ means that the sequence~$ \{A_n\}_{n \geq 0} \subset \mathcal{B}(E) $ occurs infinitely often, that is, $ \sum_n 1_{A_n} = \infty $.

The definitions of aperiodicity, irreducibility and recurrence for Markov chains and their transition kernels is crucial for the concept of ergodicity and convergence. For general state spaces, irreducibility is defined with respect to $\sigma$-finite measure~$\nu$. A transition kernel~$P$ on~$ \left( E, \mathcal{B}(E) \right) $ is called \textit{$\nu$-irreducible} if $\nu(E) > 0 $ and for each $x \in E$ and each $A \in \mathcal{B}(E)$, there exists an integer $n= n(x,A) \geq 1$ such that~$ P^n (x,A) > 0$. For our purposes, it is natural to take $\nu = \pi^{N}$ or $ \nu = \lambda^{N} $ as $\pi^{N}$ is absolutely continuous with respect to the $N$-dimensional Lebesgue measure~$\lambda^{N}$. In contrast to the classical notion of irreducibility for countable state spaces~$E$ which states that the transtion kernel has to have positive probability of eventually reaching any state from any other state, the notion of $ \nu $-irreducibility is weaker. Here, we want that any subset $B \in \mathcal{B}(E) $ with positive measure under $ \nu $ is eventually reachable with positive probability from any state~$ x \in E $. The usual notion of irreducibility on countable state spaces corresponds to $\nu$-irreducibility with respect to counting measure.

A $\nu$-irreducible transition kernel~$P$ is called \textit{periodic}, if there exists an integer~$d \geq 2$ and a sequence~$\{ E_0, E_1, \dots, E_{d-1} \}$ of $d$~nonempty disjoint sets in~$\mathcal{B}(E)$ such that for all~$i=0,\dots, d-1$ and all~$x \in E_i$: $ P(x, E_j) =1 $ for $ j = i + 1 $ (mod $d$). Otherwise the kernel is called \textit{aperiodic}.

A further crucial concept in the convergence theory of general state space chains is recurrence. A sufficient definition for the present context is as follows. A $\nu$-irreducible chain~$(x_k)_{k \geq 0} $ with invariant distribution~$\nu$ is \textit{recurrent} if, for each~$A \in \mathcal{B}(E) $ with $\nu(A) > 0 $, 
\begin{align}
 \mathbb{P}_x (x_k \in A \; i.o. ) & \; > 0 \qquad \forall x \in E, \\
 \mathbb{P}_x (x_k \in A \; i.o.) & \; = 1 \qquad \text{ for $\nu$-almost all } x.
\end{align}
The chain is \textit{Harris recurrent} if $ \mathbb{P}_x(x_k \in A \; i.o.) = 1 $ for all $x \in E$. In a discrete setup, the recurrence of a state is equal to a guarantee of a sure return. In a general setup, we have to consider elements of the $\sigma$-field~$\mathcal{B}(E)$ but the interpretation stays the same. Obviously, Harris recurrence is a stronger notion as the statement is independent of the measure~$\nu$. Moreover, a chain is called \textit{positive recurrent} if the total mass of the invariant measure is finite; otherwise it is \textit{null recurrent}. In the case of Metropolis-Hastings methods, the invariant measure~$\pi^{N}$ is a probability measure and hence finite. Therefore, every recurrent Metropolis- Hastings chain is positive recurrent. Finally, a Markov chain is called \textit{ergodic} if it is positive Harris recurrent and aperiodic. In other words, ergodicity imply that for all or for ‘‘most’’ starting values $x \in E$, the distribution of th chain converges to the invariant distribution in a suitable sense. This interpretation is linked to ergodicity via the following statement taken from~\autocite{Tierny1994}(Theorem 1).

\begin{thm}
 Suppose $P$ is $\nu$-irreducible and $\nu$-invariant with $\nu$ a finite measure. Then $P$ is positive recurrent and $\nu$ is the unique invariant distribution of $P$. If $P$ is also aperiodic, then, for $\nu$-almost all $x \in E$,
 \begin{equation}
 \label{MH - convergence in TV-norm - general}
  \| P^n (x, \cdot) - \nu \|_{TV} \to 0.
 \end{equation}
 If $P$ is Harris recurrent, then the convergence occurs for all $x \in E$.

\end{thm}

A comprehensive proof can be found in~\autocite{Athreya1996}. Reversely, it can be shown (see~\autocite{Tierny1994}) that if the convergence in~(\ref{MH - convergence in TV-norm - general}) holds for all $x \in E$, then the chain is $\nu$-irreducible, aperiodic, positive Harris recurrent and has invariant distribution $\nu$. Hence, the notion of ergodicity is the desired property for Metropolis-Hastings chains as ergodic chains converge to their invariant distribution.


It rests to show, the the Metropolis-Hastings chain~$x^N$ or the corresponding Metropolis-Hastings kernel~$P^{N}$ as defined in~(\ref{MH-TransitionKernelOfMHChain}) are $\pi^{N}$-irreducible, aperiodic and, to obtain convergence for any initial value, Harris recurrent. As mentioned before, the measure $\pi^{N}$ is a probablity measure and therefore finite. There exists several simple and less simple conditions for the proposal kernel~$Q$ and the target distribution~$\pi^{N}$ such that the resulting MH chain is $\pi^{N}$-irreducible and aperiodic. We will state one condition which is easy to check and widely applicable. Additionally, we will see that this suffices to prove Harris recurrence.

The following result is taken from Roberts and Tweedie~\autocite{RobertsTweedie1996} and relies on the idea that if the proposal density~$q$ is positive allows for moves in a small neighborhood of the actual position and the target distribution~$\pi^{N}$ is positive such that the acceptance probability is strictly positive in this neighborhood, then any subset of the support of~$\pi^{N}$ can be reached in finite steps.

\begin{lemma}
  Assume the target distribution~$\pi^{N}$ is bounded and positive on every compact set of its support. If there exist positive numbers~$\varepsilon$ and~$\delta$ such that:
  \begin{equation}
   \label{MH - Conditions for irrducibility}
   q(x, y) > \varepsilon \qquad \text{ if } \; |x-y| < \delta,
  \end{equation}
  then the Metropolis-Hastings Markov chain~$x^{N}$ is $\pi^{N}$-irreducible and aperiodic.

\end{lemma}

Note, that we assumed in Remark~\ref{Rem-SupportOfProposals} the support of~$\pi^{N}$ as connected. Due to Tierny~\autocite{Tierny1994}, we can state the following for general Metropolis-Hasting algorithms.

\begin{lemma}
 \label{MH - Harris recurrence for MH algorithms}
 Suppose $P^{N}$ as defined in~(\ref{MH-TransitionKernelOfMHChain}) is a $\pi^N$-irreducible Metropolis-Hastings transition kernel. Then $P^{N}$ is Harris recurrent.
\end{lemma}

The statement follows from the characterization of Harris recurrence via bounded harmonic functions and the fact that under the assumption of~$\pi^{N}$-irreducibility, the probability of leaving the current state~(\ref{MH-TransitionKernelOfMHChain}) is stictly less than 1.


In the end, we can state the main result due to Robert and Casella (Theorem 7.4,~\autocite{Robert2005}): the convergence and ergodicity result for Metropolis-Hastings Markov chains.

\begin{thm}
\label{Theorem-Ergodicity}
 Let  $ \{ x^{k,N} \}_{k} $ be a (general) Metropolis-Hastings Markov chain with target distribution $ \pi^{N} $.
 \begin{enumerate}
  \item If $ f \in L^1( \pi^{N} ) $, then
  \begin{equation}
  \label{Theorem-Ergodicity-Statement1}
   \lim_{K \to \infty} \frac{1}{K} \sum_{k = 1}^{K} f \left( x^{k,N} \right) = \int_E f(x) \; \pi^{N}(dx) \qquad \pi^{N}-a.e
  \end{equation}
  
  \item If in addition, $ \{ x^{k,N} \}_{k} $ is aperiodic, then
  \begin{equation}
  \label{Theorem-Ergodicity-Statement2}
   \lim_{n \to \infty} \left\| \int_E \left( P^{N} \right)^n (x, \, \cdot \, ) \mu(dx) -  \pi^{N}   \right\|_{TV} = 0
  \end{equation}
  for every initial distribution $\mu$, where $ \left( P^{N} \right)^n (x, \, \cdot \, ) $ denotes the kernel for $n$ transitions, with (general) MH transition kernels as given in equation~(\ref{MH-TransitionKernelOfMHChain}).

 \end{enumerate}
  
\end{thm}






\subsection{The Random Walk Metropolis-Hastings algorithm}
\label{MH-RWM}

A quite natural approach for the practical construction of a Metropolis-Hastings algorithm are random walk proposals: taking the previously simulated state to generate the following. In other words, the algorithm explores the local neighborhood of the current state to find the next proposal and therefore possible next state of the Markov chain.

The proposal kernel $Q$ with density $ q(x,y) $ in algorithm~\ref{Algo-MH} is allowed to depend on the current state $x$. Thus, a first choice to consider is to simulate the new proposal $ y $ by perturbating the current state, i.e.,
\begin{equation}
 \label{MH-RWM:RWM-proposals, First choice}
 y = x + \xi,
\end{equation}
where $ \xi $ is a random pertubation independent from $ x $. This means in terms of the Metropolis-Hastings algorithm, that the proposal density $ q(x,y) $ is now of the form $ q(y-x) $, i.e., the transition from $x$ to $y$ depends only on the difference of these two states. Without the Metropolizing acceptance and rejecting step in algorithm~\ref{Algo-MH}, the Markov chain associated with $q(x-y)$ is a random walk.


The convergence and ergodicity results of Section \ref{MH-ConvergenceProperties} naturally apply in this particular setup. Considering the assumption in equation~(\ref{MH - Conditions for irrducibility}), if the distribution of the pertubations $q$ is positive in a neighborhood of 0, the generated Metropolis-Hastings Markov chain $ x^{N} = \{ x^{k,N} \}_{k} $ is $ \pi^{N} $-irreducible and aperiodic, and therefore ergodic. A widely used and important choice for the distribution of pertubations and therefore the proposal distribution $ q(x,y) $ are the normal distributions. Hence, we will consider in the sequel that the proposal kernel is given by
\begin{equation}
\label{RWM-GaussianProposalKernel}
 Q(x. \, \cdot \,) := \mathcal{N}(x, \sigma^2 I_{N} ),
\end{equation}
where $ \mathcal{N}(x, \sigma^2 I_{N} ) $ denotes the $N$-dimensional normal (or Gaussian) distribution with mean $x \in E$ and covariance matrix $ \sigma^2 I_{N} $ with $ \sigma^2 > 0 $ and $ I_{N} $ the $N$-dimensional identity matrix. We can express the proposal density $ q(x,y) $ by:
\begin{equation}
 q(x,y) = q(y-x) \varpropto  \exp{ \left( - \frac{1}{2 \sigma^2} \left\| y-x \right\|^2  \right) }.
\end{equation}

Recall as mentioned in Remark~\ref{Rem-Omitting constants in densities} that the Metropolis-Hastings algorithm only considers ratios of densities. Thus normalizing constants like $ \left( (2 \pi)^{N} N \sigma^2 \right)^{-1/2} $ in the case of the multivariate normal distribution are omitted. Note, that in this particular case $\pi$ denotes the mathematical constant.

It can be easily seen, that these proposal densities are positive in a neighborhood of 0 for any $ \sigma^2 > 0 $. Moreover, $ q(x,y) $ is symmetric in $x$ and $y$ as it only depends on the squared distance of $x$ and $y$. This leads to a slightly simpler formulation of the Metropolis-Hastings algorithm, the random walk Metropolis (RWM) algorithm~\ref{Algo-RWM}.

Note for the following discussion, that we do not have fixed a proposal variance $ \sigma^2 > 0 $. An appropriate choice of $ \sigma^2 $ will be the key in the optimal scaling of RWM. See Section ???.


\IncMargin{1em}
\begin{algorithm}[htb]
\TitleOfAlgo{Random walk Metropolis}
\DontPrintSemicolon

\KwData{Initial state $ x^{0,N} $, proposal variance $ \sigma^2 $ and \mbox{number of iterations $ M > 0 $}}
\KwResult{$\pi^{N}$-invariant Markov chain $ \{ x^{k,N} \}_{0 \leq k \leq M} $}

\BlankLine

\For{$ k \leftarrow 1 $ \KwTo $M$}
{
  Generate proposal: $ y^{k,N} \stackrel{D}{\thicksim} \mathcal{N}\left(x^{k,N}, \; \sigma^2 I_N\right) $\;
  Set acceptance probability:
  \begin{equation*}
   \alpha^{N} ( x^{k,N}, y^{k,N} ) := 1 \wedge \dfrac{\pi^{N}(y^{k,N}) }{\pi^{N}(x^{k,N})}.    
  \end{equation*}\label{RWMAlgo-AcceptanceProba}
  Generate $ U \stackrel{D}{\thicksim} \text{Unif}(0,1) $\;
  \If { $ U < \alpha^{N} ( x^{k,N}, y^{k,N} ) $ }{ accept and set $ x^{k+1,N} = y^{k,N} $}
  \Else {reject and set $ x^{k+1,N} = x^{k,N} $}

}
\caption{Random walk Metropolis algorithm with Gaussian proposals}\label{Algo-RWM}
\end{algorithm}\DecMargin{1em}


\begin{rem}
 From another point of view, the RWM proposals can be obtained by discretizing a Brownian motion. Choosing $ \sigma^2 > 0 $ as parameter quantifying the size of the
discrete time increment, we can write
\begin{equation}
 y = x + \sigma \; Z^N, \qquad Z^N \stackrel{D}{\thicksim} \mathcal{N}\left( 0, I_N \right),
\end{equation}
where we used the scaling property of Gaussian random variables. Note that the quantity $ \sigma^2 $ is the proposal variance as well as the discrete time step and that the Gaussian proposal kernels in~(\ref{RWM-GaussianProposalKernel}) with covariance matrix $ \sigma^2 I_N $ corresponds to the above representation as discretized Brownian motion with stepsize $ \sigma^2 $.
\end{rem}


 

\subsection{The Metropolis adjusted Langevin algorithm}
\label{MH-MALA}

An alternative and more sophisticated proposal for the Metropolis-Hastings algorithm can be derived from diffusion theory. The basic idea of this approach is to find a diffusion process (or stochastic differential equation) so that in continuous time it converges to the target distribution $ \pi^{N} $ under suitable regularity conditions and then to discretize the process to implement the method. In principle this should be a good choice of $q$, since even before 'Metropolizing' using~(\ref{MH-Acceptance probability definition}) the candidate chain approximates the target distribution $ \pi^{N} $ more purposeful than a simple random walk candidate.

Our formal definitions are as follows. We assume that the density $ \pi ^{N} $W is everywhere non-zero and differentiable so that $ \nabla \log \pi^{N}(x) $ is well defined. The  Langevin diffusion $L$  is defined by the $N$-dimensional stochastic differential equation
\begin{equation}
 \label{MALA-OverdampedContinuousLangevinDiffusion}
 dL_t = dB_t + \frac{1}{2} \nabla \log \pi^{N}(L_t)dt,
\end{equation}
where $B$ is a $N$-dimensional standard Brownian motion. Under some suitable regularity conditions on $ \nabla \log \pi^{N}(x) $, i.e., continuously differentiable and quadratically bounded, one can show that the Langevin diffusion is non-explosive with $ \pi^{N} $ as invariant measure to which it also converges. See for more details Theorem 2.1 or more generally Section 2 of~\autocite{TweedieRoberts1996}. To be precise, the diffusion defined in equation~(\ref{MALA-OverdampedContinuousLangevinDiffusion}) is known as overdamped Langevin dynamics in physics. Nevertheless most mathematical publications drop the term overdamped. We will do the same.


The natural discrete approximation of the continuous diffusion $L$ can be written as
\begin{equation}
 \label{MALA-Discrete Approximation of Langevin}
 x^{k+1,N} = x^{k,N} + \sigma Z^N + \frac{\sigma^2}{2} \nabla \log \pi^{N} \left( x^{k,N} \right),  
\end{equation}
where $ Z^N \stackrel{D}{\thicksim} \mathcal{N}\left( 0, I_N \right) $ and $\sigma^2 > 0 $ is the choosen step variance corresponding to the discrete time increment. However these discrete time approximations can have a vastly different asymptotic behavior as the original Langevin diffusion (\ref{MALA-OverdampedContinuousLangevinDiffusion}). Especially, the generated Markov chain (\ref{MALA-Discrete Approximation of Langevin}) can be transient regardless of how small the discrete time step $ \sigma^2 $ is choosen, see \autocite{TweedieRoberts1996}, Theorem 3.2 for further results and sufficient conditions on $ \pi^{N} $ and $ \sigma^2 $ such that these unadjusted Langevin approximations may behave well.

We therefore introduce a modification to prevent or better to correct this undesirable behavior. Therefore, we treat (\ref{MALA-Discrete Approximation of Langevin}) as a regular Metropolis-Hastings proposal distribution and perform a acceptance-rejection step according to (\ref{MH-Acceptance probability definition}) afterwards. According to the discrete approximation, we consider that the proposal kernels are given by
\begin{equation}
\label{MALA-GaussianProposalKernel}
 Q(x. \, \cdot \,) := \mathcal{N}(x + \frac{\sigma^2}{2} \nabla \log \pi^{N} \left( x \right),\; \sigma^2 I_{N} ),
\end{equation}
where $ \mathcal{N}(x, \sigma^2 I_{N} ) $ denotes the $N$-dimensional normal (or Gaussian) distribution with mean $x + \frac{\sigma^2}{2} \nabla \log \pi^{N} \left( x \right) \in E$ and covariance matrix $ \sigma^2 I_{N} $ with $ \sigma^2 > 0 $ and $ I_{N} $ the $N$-dimensional identity matrix. We can express the proposal density $ q(x,y) $ by:
\begin{equation}
 q(x,y)  \varpropto  \exp{ \left( - \frac{ 1}{2 \sigma^2}  \left\| y - x + \frac{\sigma^2}{2} \nabla \log \pi^{N} \left( x \right) \right\|^2 \right) }.
\end{equation}

Hence, the original Metropolis-Hastings algorithm can be rewritten as MALA algorithm, see Algorithm \ref{Algo-MALA}.

\IncMargin{1em}
\begin{algorithm}[htb]
\TitleOfAlgo{Metropolis adjusted Langevin}
\DontPrintSemicolon

\KwData{Initial state $ x^{0,N} $, proposal variance $ \sigma^2 $ and \mbox{number of iterations $ M > 0 $}}
\KwResult{$\pi^{N}$-invariant Markov chain $ \{ x^{k,N} \}_{0 \leq k \leq M} $}

\BlankLine

\For{$ k \leftarrow 1 $ \KwTo $M$}
{
  Generate proposal: $ y^{k,N} \stackrel{D}{\thicksim} \mathcal{N}\left(x^{k,N} + \frac{\sigma^2}{2} \nabla \log \pi^{N}(x^{k,N}), \; \sigma^2 I_N\right) $\;
  Set acceptance probability:
  \begin{align*}
   \alpha^{N} & ( x^{k,N}, y^{k,N} )  := \\ 
   & 1 \wedge  \dfrac{\pi^{N}(y^{k,N}) }{\pi^{N}(x^{k,N})} \cdot
    \dfrac{ \exp{\left( - \frac{1}{2\sigma^2} \left\| y^{k,N} - x^{k,N} - \frac{\sigma^2}{2} \nabla \log \pi^{N}(x^{k,N}) \right\|^2 \right)} }{ \exp{\left( - \frac{1}{2\sigma^2} \left\| x^{k,N} - y^{k,N} - \frac{\sigma^2}{2} \nabla \log \pi^{N}(y^{k,N}) \right\|^2 \right)} }.    
  \end{align*}\label{MALAAlgo-AcceptanceProba}
  Generate $ U \stackrel{D}{\thicksim} \text{Unif}(0,1) $\;
  \If { $ U < \alpha^{N} ( x^{k,N}, y^{k,N} ) $ }{ accept and set $ x^{k+1,N} = y^{k,N} $}
  \Else {reject and set $ x^{k+1,N} = x^{k,N} $}

}
\caption{Metropolis adjusted Langevin algorithm}\label{Algo-MALA}
\end{algorithm}\DecMargin{1em}


\begin{rem}
 Note that the proposal distribution given through the discrete approximation of the Langevin diffusion (\ref{MALA-Discrete Approximation of Langevin}) is quite natural since it corresponds to a simplified second-order approximation of $ \pi^{N} $, see Section 7.8.5 in \autocite{Robert2005} for further details.
\end{rem} 

Similar to the RWM, the MALA proposals depend on the parameter $ \sigma^2 > 0 $ which is again the proposal variance or discrete time increment. 

To prove the assumptions of convergence for the MALA proposals (in particular~(\ref{MH - Conditions for irrducibility}), it is easily seen that as we use again a Gaussian density which is continuously differentiable and positive everywhere, the generated Metropolis-Hastings Markov chain converges towards the target distribution in distribution. Note that for similar results on the geometric ergodicity or higher convergence rates as for the RWM proposals more strict assumptions on the target distribution $ \pi^{N} $ are needed, see for further refenrences~\autocite{RobertsTweedie1996}.